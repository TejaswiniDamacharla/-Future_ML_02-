# -*- coding: utf-8 -*-
"""Task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z_e0H8BURDAMeB6D68IGjgg5AUdo88yX
"""

from google.colab import files
uploaded =files.upload()

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("Churn_Modelling.csv")

# Drop unnecessary columns
df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)

# Encode categorical columns
le = LabelEncoder()
for col in ['Geography', 'Gender']:
    df[col] = le.fit_transform(df[col])

# Check target column
print("Target column distribution:\n", df['Exited'].value_counts())

from sklearn.model_selection import train_test_split

# Features and target
X = df.drop(columns=['Exited'])
y = df['Exited']

# Train/Test split with stratification to preserve class distribution
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# Check class distribution in splits
print("Training target distribution:\n", y_train.value_counts())
print("Testing target distribution:\n", y_test.value_counts())

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Features and target
X = df.drop(columns=['Exited'])
y = df['Exited']

# Train/Test split with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# Scale numeric features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Step 5 completed: Data split and scaled.")

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# Scale numeric features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize and train Logistic Regression
model = LogisticRegression(max_iter=2000, random_state=42)  # increase iterations
model.fit(X_train_scaled, y_train)

print("Step 6 completed: Logistic Regression trained successfully!")

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

# Predict on test set
y_pred = model.predict(X_test_scaled)
y_prob = model.predict_proba(X_test_scaled)[:, 1]  # probability of churn

# Evaluate model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_prob))

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Get feature importance from coefficients
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': np.abs(model.coef_[0])  # absolute value of coefficients
}).sort_values(by='Importance', ascending=False)

# Display the feature importance table
print(feature_importance)

# Plot feature importance
plt.figure(figsize=(10,6))
plt.barh(feature_importance['Feature'], feature_importance['Importance'])
plt.xlabel("Coefficient Magnitude")
plt.title("Feature Importance - Logistic Regression")
plt.gca().invert_yaxis()  # highest importance on top
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Churn by Geography
plt.figure(figsize=(8,5))
sns.countplot(x='Geography', hue='Exited', data=df)
plt.title("Churn by Geography")
plt.xlabel("Geography")
plt.ylabel("Count")
plt.show()

# Churn by Gender
plt.figure(figsize=(8,5))
sns.countplot(x='Gender', hue='Exited', data=df)
plt.title("Churn by Gender")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()

# Churn by Tenure (example: histogram)
plt.figure(figsize=(8,5))
sns.histplot(data=df, x='Tenure', hue='Exited', multiple='stack', bins=10)
plt.title("Churn by Tenure")
plt.xlabel("Tenure (Years)")
plt.ylabel("Count")
plt.show()

# Optional: Churn by Age
plt.figure(figsize=(8,5))
sns.histplot(data=df, x='Age', hue='Exited', multiple='stack', bins=15)
plt.title("Churn by Age")
plt.xlabel("Age")
plt.ylabel("Count")
plt.show()